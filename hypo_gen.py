import os
from google import genai
from google.genai import types  # ì´ importê°€ í•µì‹¬!
import json
from datetime import datetime

def safe_file_read(file_path):
    """ì•ˆì „í•œ íŒŒì¼ ì½ê¸° í•¨ìˆ˜"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return None
    except Exception as e:
        print(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        return None

def generate_hypotheses_with_gemini(integrated_prompt, api_key, model="gemini-2.5-flash"):
    """
    ìˆ˜ì •ëœ Gemini API í˜¸ì¶œ í•¨ìˆ˜
    """
    client = genai.Client(api_key=api_key)
    
    try:
        response = client.models.generate_content(
            model=model,
            contents=integrated_prompt,
            config=types.GenerateContentConfig(
                temperature=0.7,
                max_output_tokens=4000,
                top_p=0.9
            )
        )
        
        print("API í˜¸ì¶œ ì„±ê³µ!")
        
        return {
            "success": True,
            "response": response.text,
            "model": model,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"âŒ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return {
            "success": False,
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

def main():
    # íŒŒì¼ ì½ê¸°
    pm_text = safe_file_read('results/pm_text.txt')
    query = '''
        Based on the textual abstraction of this business process, 
        please provide:
        1. Three specific optimization hypotheses with supporting data
        2. Root cause analysis of performance bottlenecks
        3. Actionable recommendations with expected measurable impact
        4. Simulation scenarios for testing improvements
    '''
    # synthesized_explanation = safe_file_read('results/enhanced_sax4bpm_prompt.txt')
    
    if pm_text is None:
        print("âŒ í•„ìš”í•œ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # í”„ë¡¬í”„íŠ¸ ìƒì„±
    total_prompt = f'''Human: {query}
                        process abstraction: {pm_text}'''
#   additional explanation: {synthesized_explanation}'''
    
    # total_prompt = f'''process abstraction: {pm_text}'''
    
    print(f"í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ (ê¸¸ì´: {len(total_prompt)} ë¬¸ì)")
    
    # API í˜¸ì¶œ
    api_key = 'your-key'
    result = generate_hypotheses_with_gemini(total_prompt, api_key)
    
    # ê²°ê³¼ ì²˜ë¦¬
    if result["success"]:
        print("ê°€ì„¤ ìƒì„± ì„±ê³µ!")
        print("\n--- ìƒì„±ëœ ê°€ì„¤ ---")
        print(result["response"])
        
        # íŒŒì¼ë¡œ ì €ì¥
        with open('generated_hypotheses.txt', 'w', encoding='utf-8') as f:
            f.write(result["response"])
        print("\nğŸ“ ê²°ê³¼ê°€ 'generated_hypotheses.txt'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    else:
        print(f"ê°€ì„¤ ìƒì„± ì‹¤íŒ¨: {result['error']}")

if __name__ == "__main__":
    main()